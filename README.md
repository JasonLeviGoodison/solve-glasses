This is meant purely for educational purposes

In it, we built an android app and loaded it into a Vuzix headset. We integrated the mic, camera, and display to feed all context into an OpenAI call whenever someone says the keyword "solve".

It slowly scrolls down so the user can see what its saying.


This legitmately would never work in a real world scenario, which is why I am putting it up here for example only
